<!DOCTYPE html>
<html lang="en"><head><title>Large Language Models Struggle to Learn Long-Tail Knowledge</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inconsolata&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Rubik:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Large Language Models Struggle to Learn Long-Tail Knowledge"/><meta property="og:description" content="In this paper, the authors show that a language model’s ability to answer fact-based questions is dependent on the related number of documents it pre-trained on ..."/><meta property="og:image" content="https://akash7243.github.io/homepage/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="In this paper, the authors show that a language model’s ability to answer fact-based questions is dependent on the related number of documents it pre-trained on ..."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="Paper-Reading/LLMs-Struggle-to-Learn-Long-Tail-Knowledge"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"></div><div class="center"><div class="page-header"><header><div class="explorer mobile-only"><button type="button" id="explorer" class="collapsed" data-behavior="link" data-collapsed="collapsed" data-savestate="true" data-tree="[{&quot;path&quot;:&quot;Daily-Notes&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Paper-Reading&quot;,&quot;collapsed&quot;:true}]" data-mobileonly="true"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><div id="explorer-content"><ul class="overflow" id="explorer-ul"><li><div class="folder-outer open"><ul style="padding-left:0;" class="content" data-folderul><li><div class="folder-outer "><ul style="padding-left:0;" class="content" data-folderul></ul></div></li><li><div class="folder-container"><div data-folderpath="Daily-Notes"><a href="../Daily-Notes" data-for="Daily-Notes" class="folder-title">Daily Notes</a></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Daily-Notes"><li><a href="../Daily-Notes/Mech-Interp,-Variables,-Interpretable-Bases" data-for="Daily-Notes/Mech-Interp,-Variables,-Interpretable-Bases">A note on a note on mechanistic interpretability, variables, and importance of interpretable bases</a></li><li><a href="../Daily-Notes/Linear-Decoding-and-Deep-Nets-with-Neural-Collapse" data-for="Daily-Notes/Linear-Decoding-and-Deep-Nets-with-Neural-Collapse">Linear Decoding and Deep Nets with Neural Collapse</a></li><li><a href="../Daily-Notes/Masked-Language-Modeling" data-for="Daily-Notes/Masked-Language-Modeling">Masked Language Modeling</a></li><li><a href="../Daily-Notes/Toy-Models-of-Superposition" data-for="Daily-Notes/Toy-Models-of-Superposition">Notes on Toy Models of Superposition</a></li><li><a href="../Daily-Notes/Some-definitions-in-Information-Theory" data-for="Daily-Notes/Some-definitions-in-Information-Theory">Some definitions in Information Theory</a></li></ul></div></li><li><div class="folder-container"><div data-folderpath="Paper-Reading"><a href="../Paper-Reading" data-for="Paper-Reading" class="folder-title">Paper Reading</a></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Paper-Reading"><li><a href="../Paper-Reading/How-Does-IB-help-DL" data-for="Paper-Reading/How-Does-IB-help-DL">How Does Information Bottleneck Help Deep Learning?</a></li><li><a href="../Paper-Reading/Language-Models-for-Text-Classification---Is-ICL-Enough" data-for="Paper-Reading/Language-Models-for-Text-Classification---Is-ICL-Enough">Language Models for Text Classification: Is In-Context Learning Enough?</a></li><li><a href="../Paper-Reading/LLMs-Struggle-to-Learn-Long-Tail-Knowledge" data-for="Paper-Reading/LLMs-Struggle-to-Learn-Long-Tail-Knowledge">Large Language Models Struggle to Learn Long-Tail Knowledge</a></li></ul></div></li></ul></div></li><li id="explorer-end"></li></ul></div></div><h1 class="page-title"><a href="..">Akash Sharma</a></h1><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></header><div class="popover-hint"><h1 class="article-title">Large Language Models Struggle to Learn Long-Tail Knowledge</h1><p show-comma="true" class="content-meta"><span>Jun 17, 2024</span><span>2 min read</span></p><ul class="tags"><li><a href="../tags/llms" class="internal tag-link">llms</a></li><li><a href="../tags/empirical" class="internal tag-link">empirical</a></li></ul></div></div><article class="popover-hint"><p>In this paper, the authors show that a language model’s ability to answer fact-based questions is dependent on the related number of documents it pre-trained on. The general observation is that lesser the number of relevant (to the QA pair) documents the model pre-trained on, worse is its QA performance for that particular pair.</p>
<h1 id="motivating-questions">Motivating Questions<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#motivating-questions" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<ol>
<li>Many concepts or much knowledge appears rarely on the Internet (primary source for LLM training), are language models able to learn this knowledge well? How is the LLM’s ability to answer the question affected by the number of related documents seen during the pre-training?</li>
<li>If there is a correlation between the number of relevant documents and the QA performance, does it also mean causation?</li>
<li>How can such long-tail knowledge be better captured? How does model scaling and retrieval-augmentation affect performance on long-tail knowledge?</li>
<li><em>What kind</em> of knowledge language models capture <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">−</span></span></span></span> do they learn “easy” facts that appear more frequently in the pre-training data?</li>
</ol>
<h1 id="how">How?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#how" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<blockquote class="callout question" data-callout="question">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Question</p></div>
                  
                </div>
<p><strong>How do they find the relevant documents and count them?</strong></p>
<p>Entity linking the pre-training datasets and the counting documents with the same entities as the QA pair. DBpedia Spotlight Entity Linker is run at massively distributed scale and the entities are linked to DBpedia or Wikidata IDs using traditional entity linking methods. This lets us store the document indices for each entity.</p>
<p>Next, the QA pair is entity linked and the entities from both the question and ground-truth answer is extracted. Once this is done, count the number of documents from the earlier pre-trained dataset entity linking for the extracted QA entities where both the question entity and the answer entity co-occur.</p>
</blockquote>
<p><img src="../images/entitylinkinglongtail.png" width="auto" height="auto" alt/></p>
<h1 id="references">References<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#references" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>[1] Kandpal, Nikhil, et al. “Large language models struggle to learn long-tail knowledge.” <em>International Conference on Machine Learning</em>. PMLR, 2023.</p></article></div><div class="right sidebar"><div class="spacer desktop-only"></div><div class="spacer desktop-only"></div><div class="spacer desktop-only"></div><div class="spacer desktop-only"></div><div class="explorer desktop-only"><div id="explorer-content"><ul class="overflow" id="explorer-ul"><li><div class="folder-outer open"><ul style="padding-left:0;" class="content" data-folderul><li><div class="folder-outer "><ul style="padding-left:0;" class="content" data-folderul></ul></div></li><li><div class="folder-container"><div data-folderpath="Daily-Notes"><a href="../Daily-Notes" data-for="Daily-Notes" class="folder-title">Daily Notes</a></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Daily-Notes"><li><a href="../Daily-Notes/Mech-Interp,-Variables,-Interpretable-Bases" data-for="Daily-Notes/Mech-Interp,-Variables,-Interpretable-Bases">A note on a note on mechanistic interpretability, variables, and importance of interpretable bases</a></li><li><a href="../Daily-Notes/Linear-Decoding-and-Deep-Nets-with-Neural-Collapse" data-for="Daily-Notes/Linear-Decoding-and-Deep-Nets-with-Neural-Collapse">Linear Decoding and Deep Nets with Neural Collapse</a></li><li><a href="../Daily-Notes/Masked-Language-Modeling" data-for="Daily-Notes/Masked-Language-Modeling">Masked Language Modeling</a></li><li><a href="../Daily-Notes/Toy-Models-of-Superposition" data-for="Daily-Notes/Toy-Models-of-Superposition">Notes on Toy Models of Superposition</a></li><li><a href="../Daily-Notes/Some-definitions-in-Information-Theory" data-for="Daily-Notes/Some-definitions-in-Information-Theory">Some definitions in Information Theory</a></li></ul></div></li><li><div class="folder-container"><div data-folderpath="Paper-Reading"><a href="../Paper-Reading" data-for="Paper-Reading" class="folder-title">Paper Reading</a></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Paper-Reading"><li><a href="../Paper-Reading/How-Does-IB-help-DL" data-for="Paper-Reading/How-Does-IB-help-DL">How Does Information Bottleneck Help Deep Learning?</a></li><li><a href="../Paper-Reading/Language-Models-for-Text-Classification---Is-ICL-Enough" data-for="Paper-Reading/Language-Models-for-Text-Classification---Is-ICL-Enough">Language Models for Text Classification: Is In-Context Learning Enough?</a></li><li><a href="../Paper-Reading/LLMs-Struggle-to-Learn-Long-Tail-Knowledge" data-for="Paper-Reading/LLMs-Struggle-to-Learn-Long-Tail-Knowledge">Large Language Models Struggle to Learn Long-Tail Knowledge</a></li></ul></div></li></ul></div></li><li id="explorer-end"></li></ul></div></div><div class="spacer desktop-only"></div><div class="toc"><button type="button" id="toc" class="collapsed"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#motivating-questions" data-for="motivating-questions">Motivating Questions</a></li><li class="depth-0"><a href="#how" data-for="how">How?</a></li><li class="depth-0"><a href="#references" data-for="references">References</a></li></ul></div></div><div class="spacer desktop-only"></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.3</a> © 2024</p><ul><li><a href="https://github.com/akashrma">GitHub</a></li><li><a href="https://twitter.com/mathcrush247">Twitter</a></li><li><a href="https://www.linkedin.com/in/akashsharma7243/">LinkedIn</a></li></ul></footer></div></body><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script type="application/javascript">
            const socket = new WebSocket('ws://localhost:3001')
            // reload(true) ensures resources like images and scripts are fetched again in firefox
            socket.addEventListener('message', () => document.location.reload(true))
          </script><script src="../postscript.js" type="module"></script></html>